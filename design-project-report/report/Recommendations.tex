\section{Recommendations and Priorities}
\label{sec:recommendations}
\subsection{Evaluation of Our Suggestions}

Our main suggestion, the course hook in the email newsletter, can in principle immediately be implemented and tested within the current work practices at DMA. More importantly it can be evaluated without much risk or requirements from DMA. There are different ways of evaluating this and we would like to suggest some options:

\subsubsection{A/B Testing of Newsletter}
One way of testing the effect of the course hook is to do an A/B test using the newsletter: Part of the DMA members receive a newsletter with some course recommendations using the existing framework, while another part receives a newsletter where the course hooks are used. The two groups are then compared, fx on how many clicks the course hooks resulted in versus the existing way.

\subsubsection{Hook Comparisons}
We suggest several types of hooks in our solution under the assumption that different things work for different people and this holds true for doctors too. However, it could very well be that some type of hook, for instance an intro video, works exceptionally well, while others are no better or perhaps worse than just having a textual description.

A key part of our suggestion is the importance of clear, concise and specific time annotations on any and all hooks. This is another parameter that should be evaluated, as even though the type of hook might be well chosen, for example a video, if the time needed for it to work is too long. or it’s too short and not comprehensive enough, it may have no effect.

In testing both the type and time aspects of the idea, the A/B testing using the newsletter can be used again. For example to evaluate types a hook of each type could be made for a course with equal time requirements and then the newsletter recipients receive one or the other and the amount of clicks are compared. The hooks could also be sent out together and the recipients would then choose which one to click. It should be noted with this method however, that layout and positioning of the hooks could bring noise to the result.

Similarly, to evaluate time a hook of for example 7 min duration and another of 3 min duration is created and then clicks compared. A/B testing is a good approach for this, as having two of the same type of hook but with different time requirements that the doctor then chooses from, would almost certainly just favour the shortest and perhaps even bring confusion.

\subsection{Success Criteria}
The case description provided by DMA was focused on the creation of a learning platform and service. Our focus has changed to the promotion of courses instead, and this calls for a clear definition of success criteria of our solution. These success criteria should fit with DMA’s overall strategy so it’s possible to gauge whether our solutions helps achieving the goals.

Based on our understanding of the DMA strategy, the initial case description and our work, we have the following suggestions to success criteria:
\begin{description}
\item[More signed up course attendants:] As our suggestions are not strictly tied to e-learning courses but can be applied to any course, one possible criteria could be to simply have more attendants to courses. This can be measured by comparing the number of attendants to courses that DMA does on a yearly basis or by looking at the number of BMJ subscription for example.

\item[More website exposure:] Since the DMA website is a keystone in their strategy, getting more traffic and usage of the site could be a clear goal. DMA already has data on their websites exposure, so tracking that after deploying course hooks and comparing would allow evaluation of this criteria.
\end{description}

\subsection{Risks and Limitations}
Of course, there are many threats to validity regarding our proposed solutions. First of all, given the huge lack of user participation we have not been able to get a feedback on how well the Hook and Reel method works. Ideally we would have loved to create a workshop with a room full of doctors and get a genuine feedback on the use of our prototypes but that is unrealistic and very difficult.

Secondly, there are many things that depend on the quality of the hooks. It is not enough to have actually made the hook, it has to be exciting in some way that really brings out the main points of the course it is representing. Seeing as we suggest that the responsibility of the hook creation should lie in the hands of the course responsible, DMA might not be able to be in full control here.

Thirdly, we are only innovating a small aspect of the whole system. We are not designing or innovating a new platform or coming up with a new way to deliver courses, we are only innovating how it should present them. As younger doctors who are more technologically oriented start to appear and fill the seats of the older generation, the Hook and Reel method might get obsolete.

\subsection{Next step}
Early in our project we identified the doctors work practices and specifically their time constraints as a key issue in making any e-learning approach successful. Although our focus has changed to the work practices at DMA primarily, given more time we would have very much liked to observe doctors, try out our suggestions “in the wild” and generally involve more doctors to establish more intimate knowledge of their work practices.
